compute_config:
  plan_ngpus: 1
  constant_folding: true
  use_zero: true
  use_end2end: true

run_mode: run
pas_policy: autodist
micro_batch_size: 2
global_batch_size: 8
max_train_steps: 10
enable_progress_bar: false
precision: bf16
instance_name: p$(compute_config.plan_ngpus)

model:
  type: tests.cli.common.MLP
  args:
    dim: 16
    nlayers: 16

optimizer:
  type: nnscaler.HybridOptimizer
  param_clss_fn: tests.runtime.test_hybrid_optimizer.param_clss_fn_mp
  args:
    config:
      optimizers:
        - type: nnscaler.MixedPrecisionAdamW
          options:
            lr: 0.02
        - type: torch.optim.AdamW
          options:
            lr: 0.02
  clip_gnorm: 0.01

dataset:
  type: tests.cli.common.SimpleDataset
  train_args:
    dim: 16
    size: 100
  val_args:
    dim: 16
    size: 10

dataloader:
  train_args:
    drop_last: true
  val_args:
    drop_last: true

checkpoint:
  keep_last_n_checkpoints: 30
  every_n_train_steps: 1
  save_type: deduped
